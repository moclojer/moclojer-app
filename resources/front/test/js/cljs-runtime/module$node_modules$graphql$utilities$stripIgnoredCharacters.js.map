{
"version":3,
"file":"module$node_modules$graphql$utilities$stripIgnoredCharacters.js",
"lineCount":3,
"mappings":"AAAAA,cAAA,CAAA,4DAAA,CAAiF,QAAQ,CAACC,MAAD,CAAQC,OAAR,CAAgBC,MAAhB,CAAuBC,OAAvB,CAAgC,CAGzHC,MAAOC,CAAAA,cAAP,CAAsBF,OAAtB,CAA+B,YAA/B,CAA6C,CAC3CG,MAAO,CAAA,CADoC,CAA7C,CAGAH,QAAQI,CAAAA,sBAAR,CAsEAA,QAA+B,CAACC,MAAD,CAAS,CACtC,IAAMC,UAAY,GAAIC,OAAQC,CAAAA,QAAZ,EAAsBH,MAAtB,CAAA,CACdA,MADc,CAEd,IAAIE,OAAQE,CAAAA,MAAZ,CAAmBJ,MAAnB,CACEK,OAAAA,CAAOJ,SAAUI,CAAAA,IACjBC,UAAAA,CAAQ,IAAIC,MAAOC,CAAAA,KAAX,CAAiBP,SAAjB,CACd,KAAIQ,aAAe,EAGnB,KAFA,IAAIC,+BAAiC,CAAA,CAErC,CAAOJ,SAAMK,CAAAA,OAAN,EAAgBC,CAAAA,IAAvB,GAAgCC,UAAWC,CAAAA,SAAUC,CAAAA,GAArD,CAAA,CAA0D,CACxD,MAAMC,aAAeV,SAAMW,CAAAA,KAA3B;AACMC,UAAYF,YAAaJ,CAAAA,IAD/B,CAQMO,gBAAkB,CAAC,GAAIZ,MAAOa,CAAAA,qBAAX,EACvBJ,YAAaJ,CAAAA,IADU,CAIrBF,+BAAJ,GAEIS,eAFJ,EAGIH,YAAaJ,CAAAA,IAHjB,GAG0BC,UAAWC,CAAAA,SAAUO,CAAAA,MAH/C,IAKIZ,YALJ,EAKoB,GALpB,CASMa,+BAAAA,CAAYjB,MAAKkB,CAAAA,KAAL,CAAWP,YAAaQ,CAAAA,KAAxB,CAA+BR,YAAaS,CAAAA,GAA5C,CAGhBhB,aAAA,CADES,SAAJ,GAAkBL,UAAWC,CAAAA,SAAUY,CAAAA,YAAvC,CACEjB,YADF,CACkB,GAAIkB,YAAaC,CAAAA,gBAAjB,EAAmCZ,YAAalB,CAAAA,KAAhD,CAAuD,CACrE+B,SAAU,CAAA,CAD2D,CAAvD,CADlB,CAKEpB,YALF,CAKkBa,8BAGlBZ,+BAAA;AAAiCS,eAhCuB,CAmC1D,MAAOV,aA5C+B,CApExC,KAAIkB,aAAelC,OAAA,CAAQ,kDAAR,CAAnB,CAEIc,OAASd,OAAA,CAAQ,4CAAR,CAFb,CAIIS,QAAUT,OAAA,CAAQ,6CAAR,CAJd,CAMIoB,WAAapB,OAAA,CAAQ,gDAAR,CAdwG;",
"sources":["node_modules/graphql/utilities/stripIgnoredCharacters.js"],
"sourcesContent":["shadow$provide[\"module$node_modules$graphql$utilities$stripIgnoredCharacters\"] = function(global,require,module,exports) {\n'use strict';\n\nObject.defineProperty(exports, '__esModule', {\n  value: true,\n});\nexports.stripIgnoredCharacters = stripIgnoredCharacters;\n\nvar _blockString = require('../language/blockString.js');\n\nvar _lexer = require('../language/lexer.js');\n\nvar _source = require('../language/source.js');\n\nvar _tokenKind = require('../language/tokenKind.js');\n\n/**\n * Strips characters that are not significant to the validity or execution\n * of a GraphQL document:\n *   - UnicodeBOM\n *   - WhiteSpace\n *   - LineTerminator\n *   - Comment\n *   - Comma\n *   - BlockString indentation\n *\n * Note: It is required to have a delimiter character between neighboring\n * non-punctuator tokens and this function always uses single space as delimiter.\n *\n * It is guaranteed that both input and output documents if parsed would result\n * in the exact same AST except for nodes location.\n *\n * Warning: It is guaranteed that this function will always produce stable results.\n * However, it's not guaranteed that it will stay the same between different\n * releases due to bugfixes or changes in the GraphQL specification.\n *\n * Query example:\n *\n * ```graphql\n * query SomeQuery($foo: String!, $bar: String) {\n *   someField(foo: $foo, bar: $bar) {\n *     a\n *     b {\n *       c\n *       d\n *     }\n *   }\n * }\n * ```\n *\n * Becomes:\n *\n * ```graphql\n * query SomeQuery($foo:String!$bar:String){someField(foo:$foo bar:$bar){a b{c d}}}\n * ```\n *\n * SDL example:\n *\n * ```graphql\n * \"\"\"\n * Type description\n * \"\"\"\n * type Foo {\n *   \"\"\"\n *   Field description\n *   \"\"\"\n *   bar: String\n * }\n * ```\n *\n * Becomes:\n *\n * ```graphql\n * \"\"\"Type description\"\"\" type Foo{\"\"\"Field description\"\"\" bar:String}\n * ```\n */\nfunction stripIgnoredCharacters(source) {\n  const sourceObj = (0, _source.isSource)(source)\n    ? source\n    : new _source.Source(source);\n  const body = sourceObj.body;\n  const lexer = new _lexer.Lexer(sourceObj);\n  let strippedBody = '';\n  let wasLastAddedTokenNonPunctuator = false;\n\n  while (lexer.advance().kind !== _tokenKind.TokenKind.EOF) {\n    const currentToken = lexer.token;\n    const tokenKind = currentToken.kind;\n    /**\n     * Every two non-punctuator tokens should have space between them.\n     * Also prevent case of non-punctuator token following by spread resulting\n     * in invalid token (e.g. `1...` is invalid Float token).\n     */\n\n    const isNonPunctuator = !(0, _lexer.isPunctuatorTokenKind)(\n      currentToken.kind,\n    );\n\n    if (wasLastAddedTokenNonPunctuator) {\n      if (\n        isNonPunctuator ||\n        currentToken.kind === _tokenKind.TokenKind.SPREAD\n      ) {\n        strippedBody += ' ';\n      }\n    }\n\n    const tokenBody = body.slice(currentToken.start, currentToken.end);\n\n    if (tokenKind === _tokenKind.TokenKind.BLOCK_STRING) {\n      strippedBody += (0, _blockString.printBlockString)(currentToken.value, {\n        minimize: true,\n      });\n    } else {\n      strippedBody += tokenBody;\n    }\n\n    wasLastAddedTokenNonPunctuator = isNonPunctuator;\n  }\n\n  return strippedBody;\n}\n\n};"],
"names":["shadow$provide","global","require","module","exports","Object","defineProperty","value","stripIgnoredCharacters","source","sourceObj","_source","isSource","Source","body","lexer","_lexer","Lexer","strippedBody","wasLastAddedTokenNonPunctuator","advance","kind","_tokenKind","TokenKind","EOF","currentToken","token","tokenKind","isNonPunctuator","isPunctuatorTokenKind","SPREAD","tokenBody","slice","start","end","BLOCK_STRING","_blockString","printBlockString","minimize"]
}
